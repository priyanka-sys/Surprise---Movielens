{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.load_data as load_data\n",
    "import utils.Dataload as Dataload\n",
    "from pathlib import Path\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, NMF\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "from surprise.prediction_algorithms.algo_base import AlgoBase\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = data_loader.get_data('ml-100k')\n",
    "data_dir = Path('../data/movielens/ml-latest-small/ratings.csv')\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "data_raw = data_loader.get_data('ratings.csv', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evalute_model_pipeline(model_class: AlgoBase, dataset: str = 'ml-100k', \n",
    "                                     from_surprise: bool = True, \n",
    "                                     test_size: float = 0.2,\n",
    "                                     model_kwargs: dict = {}) -> (AlgoBase, dict):\n",
    "    data = data_loader.get_data(dataset, from_surprise)\n",
    "    train_set, test_set = train_test_split(data, test_size, random_state=42)\n",
    "    model = Dataload.get_trained_model(model_class, train_set, model_kwargs)\n",
    "    metrics_dict = Dataload.evaluate_model(model, test_set)\n",
    "    return model, metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x7fc94c14fdc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model, metrics_dict = train_and_evalute_model_pipeline(KNNBasic)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='907', iid='143', r_ui=5.0, est=4.762202632237946, details={'was_impossible': False}),\n",
       " Prediction(uid='371', iid='210', r_ui=4.0, est=4.211045843957054, details={'was_impossible': False}),\n",
       " Prediction(uid='218', iid='42', r_ui=4.0, est=3.4576465941225325, details={'was_impossible': False}),\n",
       " Prediction(uid='829', iid='170', r_ui=4.0, est=4.07731408042207, details={'was_impossible': False}),\n",
       " Prediction(uid='733', iid='277', r_ui=1.0, est=3.0701961367499555, details={'was_impossible': False}),\n",
       " Prediction(uid='363', iid='1512', r_ui=1.0, est=3.601462078997732, details={'was_impossible': False}),\n",
       " Prediction(uid='193', iid='487', r_ui=5.0, est=3.7561068104413047, details={'was_impossible': False}),\n",
       " Prediction(uid='808', iid='313', r_ui=5.0, est=4.54216185300126, details={'was_impossible': False}),\n",
       " Prediction(uid='557', iid='682', r_ui=2.0, est=3.6357756491341084, details={'was_impossible': False}),\n",
       " Prediction(uid='774', iid='196', r_ui=3.0, est=2.376520149285778, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.test(test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9378456428063894"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.7395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7395408044495279"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mae(predictions=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modular code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.980150596704479, 'MAE': 0.980150596704479}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model, metrics_dict = train_and_evalute_model_pipeline(KNNBasic)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x7fc94c0925e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kwargs = {'sim_options': {'user_based': False, 'name': 'pearson'}}\n",
    "my_model, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs=model_kwargs)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN user based cosine': {'RMSE': 1.0193536815834319,\n",
       "  'MAE': 1.0193536815834319},\n",
       " 'KNN user based pearson': {'RMSE': 1.0150350905205965,\n",
       "  'MAE': 1.0150350905205965},\n",
       " 'KNN item based cosine': {'RMSE': 1.0264295933767333,\n",
       "  'MAE': 1.0264295933767333},\n",
       " 'KNN item based pearson': {'RMSE': 1.041104054968961,\n",
       "  'MAE': 1.041104054968961}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_dict = {}\n",
    "\n",
    "\n",
    "model_dict_list = [\n",
    "    {\n",
    "        'model_name' : 'KNN user based with cosine similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': True, 'name': 'cosine'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'KNN user based with pearson similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': True, 'name': 'pearson'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'KNN item based with cosine similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': False, 'name': 'cosine'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'KNN item based with pearson similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': False, 'name': 'pearson'}\n",
    "    },\n",
    "]\n",
    "\n",
    "for model_dict in model_dict_list:\n",
    "    model, metrics_dict = train_and_evalute_model_pipeline(\n",
    "        model_dict['model_class'], model_kwargs = model_dict.get('model_kwargs', {}))\n",
    "    benchmark_dict[model_dict['model_name']] = metrics_dict\n",
    "    model_dict['fitted_model'] = model\n",
    "    \n",
    "\n",
    "benchmark_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_dict = {}\n",
    "\n",
    "\n",
    "model_dict_list = [\n",
    "    {\n",
    "        'model_name' : 'SVD',\n",
    "        'model_class' : SVD\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'NMF',\n",
    "        'model_class' : NMF\n",
    "    },\n",
    "    ]\n",
    "\n",
    "for model_dict in model_dict_list:\n",
    "    model, metrics_dict = train_and_evalute_model_pipeline(\n",
    "        model_dict['model_class'], model_kwargs = model_dict.get('model_kwargs', {}))\n",
    "    benchmark_dict[model_dict['model_name']] = metrics_dict\n",
    "    model_dict['fitted_model'] = model\n",
    "    \n",
    "\n",
    "benchmark_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0187  1.0078  1.0135  1.0096  1.0084  1.0116  0.0041  \n",
      "MAE (testset)     0.8084  0.7987  0.8071  0.8025  0.7994  0.8032  0.0039  \n",
      "Fit time          1.27    1.05    1.12    1.15    1.26    1.17    0.09    \n",
      "Test time         3.60    3.31    2.77    3.26    2.91    3.17    0.30    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.01872866, 1.00775992, 1.01354856, 1.00955551, 1.00843408]),\n",
       " 'test_mae': array([0.80843632, 0.79869761, 0.8071084 , 0.80245938, 0.79940892]),\n",
       " 'fit_time': (1.272223949432373,\n",
       "  1.0536251068115234,\n",
       "  1.116072177886963,\n",
       "  1.1464581489562988,\n",
       "  1.2636258602142334),\n",
       " 'test_time': (3.5992281436920166,\n",
       "  3.3081600666046143,\n",
       "  2.7677388191223145,\n",
       "  3.261117935180664,\n",
       "  2.909980058670044)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.1875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
